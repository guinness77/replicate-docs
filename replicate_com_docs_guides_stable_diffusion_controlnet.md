Docs

Search documentation`âŒ˜K`

Get started

Collapse sidebar

[Run a model from Node.js](https://replicate.com/docs/get-started/nodejs) [Run a model from Google Colab](https://replicate.com/docs/get-started/google-colab) [Run a model from Python](https://replicate.com/docs/get-started/python) [Fine-tune an image model](https://replicate.com/docs/get-started/fine-tune-with-flux)

Guides

[Build a website with Next.js](https://replicate.com/docs/guides/nextjs) [Build a Discord bot with Python](https://replicate.com/docs/guides/discord-bot) [Build an app with SwiftUI](https://replicate.com/docs/guides/swiftui) [Cache images with Cloudflare](https://replicate.com/docs/guides/cloudflare-image-cache) [Use realtime speech with OpenAI](https://replicate.com/docs/guides/openai-realtime) [Push your own model](https://replicate.com/docs/guides/push-a-model) [Push a Diffusers model](https://replicate.com/docs/guides/push-a-diffusers-model) [Push a Transformers model](https://replicate.com/docs/guides/push-a-transformers-model) [Handle webhooks with Val Town](https://replicate.com/docs/guides/build-a-webhook-notifier-with-val-town) [Deploy a custom model](https://replicate.com/docs/guides/deploy-a-custom-model) [Push a model using GitHub Actions](https://replicate.com/docs/guides/push-a-model-using-github-actions) [Set up a CI/CD pipeline](https://replicate.com/docs/guides/continuous-model-deployment) [Get a GPU on Brev](https://replicate.com/docs/guides/get-a-gpu-on-brev) [Get a GPU on Lambda Labs](https://replicate.com/docs/guides/get-a-gpu-on-lambda-labs) [Working with LoRAs](https://replicate.com/docs/guides/working-with-loras)

ComfyUI

[Craft generative AI workflows with ComfyUI](https://replicate.com/docs/guides/comfyui) [Use ComfyUI manager](https://replicate.com/docs/guides/comfyui/comfyui-manager) [Start by running the ComfyUI examples](https://replicate.com/docs/guides/comfyui/examples) [Popular ComfyUI custom nodes](https://replicate.com/docs/guides/comfyui/custom-nodes) [Run your ComfyUI workflow on Replicate](https://replicate.com/docs/guides/comfyui/run-comfyui-on-replicate) [Run ComfyUI with an API](https://replicate.com/docs/guides/comfyui/run-comfyui-with-an-api)

Hypermedia

[Build AI apps fast with hypermedia](https://replicate.com/docs/guides/hypermedia) [What is hypermedia, and why use it for AI apps?](https://replicate.com/docs/guides/hypermedia/what-is-hypermedia) [Building a face swapping app with Val Town, HTMX, and Replicate](https://replicate.com/docs/guides/hypermedia/build-hypermedia-app)

Instant ID

[Make images of real people instantly with InstantID](https://replicate.com/docs/guides/instant-id) [Run InstantID with an API](https://replicate.com/docs/guides/instant-id/run-instant-id-with-an-api)

Language models

[Prompt and run open-source large language models (LLMs)](https://replicate.com/docs/guides/language-models) [How to use open source language models](https://replicate.com/docs/guides/language-models/how-to-use) [Use cases for open source language models](https://replicate.com/docs/guides/language-models/use-cases) [Popular open source language models and their use cases](https://replicate.com/docs/guides/language-models/popular-models) [How to prompt open source large language models](https://replicate.com/docs/guides/language-models/how-to-prompt) [Advanced prompting for open source large language models](https://replicate.com/docs/guides/language-models/advanced-prompting)

Llava

[Talk to images with Llava 13B](https://replicate.com/docs/guides/llava)

Model best practices

[Best practices for Replicate models](https://replicate.com/docs/guides/model-best-practices)

Photomaker

[Generate photos of real people with Photomaker](https://replicate.com/docs/guides/photomaker)

Stable Diffusion

[Make art with Stable Diffusion](https://replicate.com/docs/guides/stable-diffusion) [How to use Stable Diffusion](https://replicate.com/docs/guides/stable-diffusion/how-to-use) [Image to image (img2img) with Stable Diffusion](https://replicate.com/docs/guides/stable-diffusion/image-to-image) [Inpainting with Stable Diffusion](https://replicate.com/docs/guides/stable-diffusion/inpainting) [Outpainting with Stable Diffusion](https://replicate.com/docs/guides/stable-diffusion/outpainting) [Fine-tuning Stable Diffusion](https://replicate.com/docs/guides/stable-diffusion/fine-tuning) [Using ControlNet with Stable Diffusion](https://replicate.com/docs/guides/stable-diffusion/controlnet) [Fast Stable Diffusion: Turbo and latent consistency models (LCMs)](https://replicate.com/docs/guides/stable-diffusion/turbo-and-latent-consistency) [A to Z of Stable Diffusion](https://replicate.com/docs/guides/stable-diffusion/glossary)

Upscaling images

[Upscale images with AI models](https://replicate.com/docs/guides/upscaling-images) [Upscaling images with Real-ESRGAN](https://replicate.com/docs/guides/upscaling-images/real-esrgan) [Fixing faces with GFPGAN and Codeformer](https://replicate.com/docs/guides/upscaling-images/gfpgan-and-codeformer) [Upscaling images with SwinIR](https://replicate.com/docs/guides/upscaling-images/swinir) [Upscaling images with ControlNet tile](https://replicate.com/docs/guides/upscaling-images/controlnet-tile) [Upscaling images with Ultimate SD Upscale](https://replicate.com/docs/guides/upscaling-images/sd-ultimate-upscale)

Whisper

[Turn speech to text with WhisperX](https://replicate.com/docs/guides/whisper) [Run WhisperX with an API](https://replicate.com/docs/guides/whisper/run-whisperx-with-an-api)

Topics

Models

[About models](https://replicate.com/docs/topics/models) [Run a model](https://replicate.com/docs/topics/models/run-a-model) [Create a model](https://replicate.com/docs/topics/models/create-a-model) [Publish a model](https://replicate.com/docs/topics/models/publish-a-model) [Model versions](https://replicate.com/docs/topics/models/versions) [Model hardware](https://replicate.com/docs/topics/models/hardware) [Private and public models](https://replicate.com/docs/topics/models/private-models) [Training destinations](https://replicate.com/docs/topics/models/models-as-training-destinations) [Delete a model](https://replicate.com/docs/topics/models/delete-a-model)

Predictions

[About predictions](https://replicate.com/docs/topics/predictions) [Create a prediction](https://replicate.com/docs/topics/predictions/create-a-prediction) [Input files](https://replicate.com/docs/topics/predictions/input-files) [Output files](https://replicate.com/docs/topics/predictions/output-files) [Prediction lifecycle](https://replicate.com/docs/topics/predictions/lifecycle) [Share a prediction](https://replicate.com/docs/topics/predictions/share-a-prediction) [Rate limits](https://replicate.com/docs/topics/predictions/rate-limits) [Safety checking](https://replicate.com/docs/topics/predictions/safety-checking) [Data retention](https://replicate.com/docs/topics/predictions/data-retention) [Streaming output](https://replicate.com/docs/topics/predictions/streaming)

Deployments

[About deployments](https://replicate.com/docs/topics/deployments) [Create a deployment](https://replicate.com/docs/topics/deployments/create-a-deployment) [View deployments](https://replicate.com/docs/topics/deployments/view-deployments) [Delete a deployment](https://replicate.com/docs/topics/deployments/delete-a-deployment)

Webhooks

[About webhooks](https://replicate.com/docs/topics/webhooks) [Set up webhooks](https://replicate.com/docs/topics/webhooks/setup-webhook) [Receive webhooks](https://replicate.com/docs/topics/webhooks/receive-webhook) [Verify webhooks](https://replicate.com/docs/topics/webhooks/verify-webhook) [Test your webhook code](https://replicate.com/docs/topics/webhooks/testing-webhook-code)

Organizations

[About organizations](https://replicate.com/docs/topics/organizations)

Billing

[About billing](https://replicate.com/docs/topics/billing)

Site policy

[About subprocessors](https://replicate.com/docs/topics/site-policy/subprocessors)

Reference

[How does Replicate work?](https://replicate.com/docs/reference/how-does-replicate-work) [Client libraries](https://replicate.com/docs/reference/client-libraries) [HTTP API](https://replicate.com/docs/reference/http) [OpenAPI schema](https://replicate.com/docs/reference/openapi) [Open source](https://replicate.com/docs/reference/open-source)

ControlNet is a method for conforming your image generations to a particular structure. It's easiest explained by an example.

Let's say you wanted to create an image of a particular poseâ€”a photo like the man below, but we want a boy doing it.

![a man in a suit](https://replicate.com/frontend-assets/man-Cnx4qr9b.png)

This is a really hard problem with default stable diffusion. We could try a prompt that describes our desired pose in detail, like this:

`a photo of a boy wearing a blue jacket looking to his right with his left arm slightly above his right`

But this probably isn't going to work. Our outputs aren't going to conform to all these instructions, and even if we got lucky and they did, we won't be able to consistently generate this pose. (why? -- my guess is because the decoder can only conform to so much? or maybe this is possible, it's just a pain?)

Enter ControlNet. ControlNet models accept two inputs:

A text prompt: `a boy wearing a blue jacket`

And a `conditioning image`. There are lots of types, but for now let's use a stick figure (often called `human pose`):

![stick figure](https://replicate.com/frontend-assets/stick-CuXy7Ft1.png)

The model then uses our pose to conform/shape/control our image into our desired structure:

![boy](https://replicate.com/frontend-assets/boy-C0pvqhSl.png)

Let's try changing our prompt, but keep the pose input the same:

"chef in kitchen"

![chef](https://replicate.com/frontend-assets/chef-CHv0HaWi.png)

"Lincoln statue"

![lincoln](https://replicate.com/frontend-assets/lincoln-CjiRK4uM.png)

Source: [ControlNet paper](https://arxiv.org/abs/2302.05543)

And voila! We can create all kinds of images that are guided by the stick figure pose.

That's the essence of ControlNet. We always provide two inputs: a `text prompt` (just like normal Stable Diffusion) and a `conditioning image`. The output is guided by our conditioning image.

![diagram](https://replicate.com/frontend-assets/nutshell-CRiQuHjx.png)

Importantly, the conditioning image isn't restricted to stick figure poses. We can provide all kinds of custom compositions for the ControlNet model to follow, like edges, depths, scribbles, segmentation and many other structures. More on that later.

## [Anchor for how-does-controlnet-work](https://replicate.com/docs/guides/stable-diffusion/controlnet\#how-does-controlnet-work) How does ControlNet work?

ControlNet was created by Stanford researchers and announced in the paper [Adding Conditional Control to Text-to-Image Diffusion Models](https://arxiv.org/pdf/2302.05543.pdf).

It's trained on top of stable diffusion, so the flexibility and aesthetic of stable diffusion is still there.

I don't want to go too in depth, but training ControlNet involves using conditioning images to teach the model how to generate images according to specific conditions. These conditioning images act like guidelines or templates. For example, if the model is to learn how to generate images of cats, it might be trained with a variety of images showing cats in different poses or environments. Alongside these images, text prompts are used to describe the scene or the object. This combination of visual and textual input helps the model understand not just what to draw (from the text) but also how to draw it (from the conditioning images).

To learn more, [check out the paper](https://arxiv.org/pdf/2302.05543.pdf). Or do what I did, and upload the paper to ChatGPT and ask it a bunch of questions.

## [Anchor for types-of-conditioning-images](https://replicate.com/docs/guides/stable-diffusion/controlnet\#types-of-conditioning-images) Types of conditioning images

There are many types of `conditioning_image`'s we can use in ControlNet. We're not restricted to our human pose. We can guide our images using edge detectors, depth maps, segmentation, sketchs, and more.

![types](https://replicate.com/frontend-assets/types-BjygEO9l.png)

The best way to see how each of these work is by example.

Let's run a selection of conditioners on the following two images with completely new prompts.

_Cyberpunk Couple_
New prompt:

Copy

```
couple embracing, summer clothes,
color photo, 50mm prime, canon, studio
portrait
```

![couple](https://replicate.com/frontend-assets/couple-Cat8qHS8.png)

_Tea Room_
New prompt:

Copy

```
a photo of a beautiful cyberpunk
cafe, dawn light, warm tones,
morning scene, windows
```

![tea](https://replicate.com/frontend-assets/tearoom-DI-QL2Dr.png)

Let's see what happens when we apply different ControlNets on these two images.
In other words, let's go through this process for each type of conditioner:

![process](https://replicate.com/frontend-assets/process-CNDRe2SS.png)

### [Anchor for canny--edge-detection](https://replicate.com/docs/guides/stable-diffusion/controlnet\#canny--edge-detection) Canny â€” Edge detection

[Canny](https://en.wikipedia.org/wiki/Canny_edge_detector) is a widely used edge detector.

Here's our tea room after going through the Canny pre-processor:

![tearoom](https://replicate.com/frontend-assets/tearoom-DI-QL2Dr.png)![canny](https://replicate.com/frontend-assets/canny-DiGJ91o_.png)

Remember our prompt from earlier?

Copy

```
"a photo of a beautiful cyberpunk
cafe, dawn light, warm tones,
morning scene, windows"
```

Now, when we generate an image with our new prompt, ControlNet will generate an image based on this prompt, but guided by the Canny edge detection:
Result

![result](https://replicate.com/frontend-assets/canny-room-k7DL88Db.png)

Here's that same process applied to our image of the couple, with our new prompt:

![couple1](https://replicate.com/frontend-assets/canny-couple-BOC3CDei.png)

### [Anchor for hed--fuzzy-edge-detection](https://replicate.com/docs/guides/stable-diffusion/controlnet\#hed--fuzzy-edge-detection) HED â€” Fuzzy edge detection

HED is another kind of edge detector. Here's our pre-processed output:

![tearoom](https://replicate.com/frontend-assets/tearoom-DI-QL2Dr.png)![hed-room](https://replicate.com/frontend-assets/hed-room-wzmsmfJS.png)

And here's our output:

![hed-room output](https://replicate.com/frontend-assets/hed-room-output-CkdiWQgu.png)

The effect of HED is a bit more clear on our cyberpunk couple:

![hed couple](https://replicate.com/frontend-assets/hed-couple-BXYqIjAo.png)

Note that many details that were lost in the Canny version are present in HED detection, like her hand placement, the angle of the overhead light, and her headpiece. Note also where HED strugglesâ€”his collar becomes a streak of hair, and her makeup becomes a shadow.
HED works really well for painting and art.

### [Anchor for m-lsd--straight-line-detection](https://replicate.com/docs/guides/stable-diffusion/controlnet\#m-lsd--straight-line-detection) M-LSD â€” Straight line detection

M-LSD is another kind of edge detection that only works on straight lines.
Here's M-LSD on our tea room:

![tea3](https://replicate.com/frontend-assets/mlsd-room-CKA_-Wpq.png)![mlsd](https://replicate.com/frontend-assets/mlsd-room-output-BHhTX89B.png)

And on our cyberpunk couple:

![mlsd-couple](https://replicate.com/frontend-assets/mlsd-couple-1D_YH2IS.png)

As you can tell, M-LSD doesn't work well hereâ€”there aren't many straight lines in the original.

### [Anchor for depth-map](https://replicate.com/docs/guides/stable-diffusion/controlnet\#depth-map) Depth Map

A depth map works by simulating the distance of parts of the image from the camera. Here's what it looks like:

![tearoom](https://replicate.com/frontend-assets/tearoom-DI-QL2Dr.png)![depth room](https://replicate.com/frontend-assets/depth-room-BBSKFrm1.png)![depth room output](https://replicate.com/frontend-assets/depth-room-output-Df5VLurq.png)

This works really well on our tea room. The frames, plants, tables and pillows are all preserved. Let's try it on our couple:

![depth couple](https://replicate.com/frontend-assets/depth-couple-C4QsmlhA.png)

Again, the composition is preserved, but it struggles with the collar and hands.

### [Anchor for open-pose-aka-human-pose](https://replicate.com/docs/guides/stable-diffusion/controlnet\#open-pose-aka-human-pose) Open pose (aka Human pose)

This one should be familiar to you! Open pose/human pose turns images of people into stick figures. Let's try it on our couple:

![pose couple](https://replicate.com/frontend-assets/pose-couple-CFALMcod.png)

The colored bars are representations of the body parts of our characters. You can see that the poses are preserved, but the detail and style is lost.

### [Anchor for scribble](https://replicate.com/docs/guides/stable-diffusion/controlnet\#scribble) Scribble

Scribble is behind the very popular "turn a sketch into a drawing" apps. I'm going to use a different example for scribble, because it works best with a doodle input conditioner. For example, here's a doodle of a cat alongside my text prompt, "an oil painting of a cat":

![cat](https://replicate.com/frontend-assets/scribble-cat-DUfDejLG.png)

Here's the same with an owl:

![owl](https://replicate.com/frontend-assets/scribble-owl-zTh1lup-.png)

### [Anchor for segmentation](https://replicate.com/docs/guides/stable-diffusion/controlnet\#segmentation) Segmentation

Segmentation breaks our image down into different segments.

![tearoom](https://replicate.com/frontend-assets/tearoom-DI-QL2Dr.png)![segment room](https://replicate.com/frontend-assets/segment-room-z3VArVVw.png)![segment room output](https://replicate.com/frontend-assets/segment-room-output-BjHza-e1.png)

We've maintained the plants, the frames, and the table, but the output is quite different. There's a bit of a fish eye effect, and we've lost the pillars in the cafe.
Here's segmentation on our couple.

![segment couple](https://replicate.com/frontend-assets/segment-couple-P2-zb5FQ.png)

### [Anchor for normal-map](https://replicate.com/docs/guides/stable-diffusion/controlnet\#normal-map) Normal map

A normal map detects the texture of an image.

![tearoom](https://replicate.com/frontend-assets/tearoom-DI-QL2Dr.png)![segment room](https://replicate.com/frontend-assets/map-room-BbOILJfm.png)![segment room output](https://replicate.com/frontend-assets/map-room-output-Bb2l6lMB.png)

This is a nice output, but it doesn't preserve our original input at all. A normal map works much better on our couple:

![segment room output](https://replicate.com/frontend-assets/map-couple-rfm4SIJu.png)

## [Anchor for how-to-use-controlnet](https://replicate.com/docs/guides/stable-diffusion/controlnet\#how-to-use-controlnet) How to use ControlNet

Using ControlNet is easy with Replicate ðŸ˜Ž. We have a collection of ControlNet models [here](https://replicate.com/collections/control-net).

![collection](https://replicate.com/frontend-assets/collection-DJVWSJOB.png)

You can get started by choosing a ControlNet model and playing around with it in our GUI. If you're a developer and want to integrate ControlNet into your app, click the API tab and you'll be able to copy and paste the API request into your codebase. Happy hacking!

![gui](https://replicate.com/frontend-assets/canny-gui-To-wMIbA.png)

[Next:Fast Stable Diffusion: Turbo and latent consistency models (LCMs)](https://replicate.com/docs/guides/stable-diffusion/turbo-and-latent-consistency)

# Docs

Get started

Collapse sidebar

[Run a model from Node.js](https://replicate.com/docs/get-started/nodejs) [Run a model from Google Colab](https://replicate.com/docs/get-started/google-colab) [Run a model from Python](https://replicate.com/docs/get-started/python) [Fine-tune an image model](https://replicate.com/docs/get-started/fine-tune-with-flux)

Guides

[Build a website with Next.js](https://replicate.com/docs/guides/nextjs) [Build a Discord bot with Python](https://replicate.com/docs/guides/discord-bot) [Build an app with SwiftUI](https://replicate.com/docs/guides/swiftui) [Cache images with Cloudflare](https://replicate.com/docs/guides/cloudflare-image-cache) [Use realtime speech with OpenAI](https://replicate.com/docs/guides/openai-realtime) [Push your own model](https://replicate.com/docs/guides/push-a-model) [Push a Diffusers model](https://replicate.com/docs/guides/push-a-diffusers-model) [Push a Transformers model](https://replicate.com/docs/guides/push-a-transformers-model) [Handle webhooks with Val Town](https://replicate.com/docs/guides/build-a-webhook-notifier-with-val-town) [Deploy a custom model](https://replicate.com/docs/guides/deploy-a-custom-model) [Push a model using GitHub Actions](https://replicate.com/docs/guides/push-a-model-using-github-actions) [Set up a CI/CD pipeline](https://replicate.com/docs/guides/continuous-model-deployment) [Get a GPU on Brev](https://replicate.com/docs/guides/get-a-gpu-on-brev) [Get a GPU on Lambda Labs](https://replicate.com/docs/guides/get-a-gpu-on-lambda-labs) [Working with LoRAs](https://replicate.com/docs/guides/working-with-loras)

ComfyUI

[Craft generative AI workflows with ComfyUI](https://replicate.com/docs/guides/comfyui) [Use ComfyUI manager](https://replicate.com/docs/guides/comfyui/comfyui-manager) [Start by running the ComfyUI examples](https://replicate.com/docs/guides/comfyui/examples) [Popular ComfyUI custom nodes](https://replicate.com/docs/guides/comfyui/custom-nodes) [Run your ComfyUI workflow on Replicate](https://replicate.com/docs/guides/comfyui/run-comfyui-on-replicate) [Run ComfyUI with an API](https://replicate.com/docs/guides/comfyui/run-comfyui-with-an-api)

Hypermedia

[Build AI apps fast with hypermedia](https://replicate.com/docs/guides/hypermedia) [What is hypermedia, and why use it for AI apps?](https://replicate.com/docs/guides/hypermedia/what-is-hypermedia) [Building a face swapping app with Val Town, HTMX, and Replicate](https://replicate.com/docs/guides/hypermedia/build-hypermedia-app)

Instant ID

[Make images of real people instantly with InstantID](https://replicate.com/docs/guides/instant-id) [Run InstantID with an API](https://replicate.com/docs/guides/instant-id/run-instant-id-with-an-api)

Language models

[Prompt and run open-source large language models (LLMs)](https://replicate.com/docs/guides/language-models) [How to use open source language models](https://replicate.com/docs/guides/language-models/how-to-use) [Use cases for open source language models](https://replicate.com/docs/guides/language-models/use-cases) [Popular open source language models and their use cases](https://replicate.com/docs/guides/language-models/popular-models) [How to prompt open source large language models](https://replicate.com/docs/guides/language-models/how-to-prompt) [Advanced prompting for open source large language models](https://replicate.com/docs/guides/language-models/advanced-prompting)

Llava

[Talk to images with Llava 13B](https://replicate.com/docs/guides/llava)

Model best practices

[Best practices for Replicate models](https://replicate.com/docs/guides/model-best-practices)

Photomaker

[Generate photos of real people with Photomaker](https://replicate.com/docs/guides/photomaker)

Stable Diffusion

[Make art with Stable Diffusion](https://replicate.com/docs/guides/stable-diffusion) [How to use Stable Diffusion](https://replicate.com/docs/guides/stable-diffusion/how-to-use) [Image to image (img2img) with Stable Diffusion](https://replicate.com/docs/guides/stable-diffusion/image-to-image) [Inpainting with Stable Diffusion](https://replicate.com/docs/guides/stable-diffusion/inpainting) [Outpainting with Stable Diffusion](https://replicate.com/docs/guides/stable-diffusion/outpainting) [Fine-tuning Stable Diffusion](https://replicate.com/docs/guides/stable-diffusion/fine-tuning) [Using ControlNet with Stable Diffusion](https://replicate.com/docs/guides/stable-diffusion/controlnet) [Fast Stable Diffusion: Turbo and latent consistency models (LCMs)](https://replicate.com/docs/guides/stable-diffusion/turbo-and-latent-consistency) [A to Z of Stable Diffusion](https://replicate.com/docs/guides/stable-diffusion/glossary)

Upscaling images

[Upscale images with AI models](https://replicate.com/docs/guides/upscaling-images) [Upscaling images with Real-ESRGAN](https://replicate.com/docs/guides/upscaling-images/real-esrgan) [Fixing faces with GFPGAN and Codeformer](https://replicate.com/docs/guides/upscaling-images/gfpgan-and-codeformer) [Upscaling images with SwinIR](https://replicate.com/docs/guides/upscaling-images/swinir) [Upscaling images with ControlNet tile](https://replicate.com/docs/guides/upscaling-images/controlnet-tile) [Upscaling images with Ultimate SD Upscale](https://replicate.com/docs/guides/upscaling-images/sd-ultimate-upscale)

Whisper

[Turn speech to text with WhisperX](https://replicate.com/docs/guides/whisper) [Run WhisperX with an API](https://replicate.com/docs/guides/whisper/run-whisperx-with-an-api)

Topics

Models

[About models](https://replicate.com/docs/topics/models) [Run a model](https://replicate.com/docs/topics/models/run-a-model) [Create a model](https://replicate.com/docs/topics/models/create-a-model) [Publish a model](https://replicate.com/docs/topics/models/publish-a-model) [Model versions](https://replicate.com/docs/topics/models/versions) [Model hardware](https://replicate.com/docs/topics/models/hardware) [Private and public models](https://replicate.com/docs/topics/models/private-models) [Training destinations](https://replicate.com/docs/topics/models/models-as-training-destinations) [Delete a model](https://replicate.com/docs/topics/models/delete-a-model)

Predictions

[About predictions](https://replicate.com/docs/topics/predictions) [Create a prediction](https://replicate.com/docs/topics/predictions/create-a-prediction) [Input files](https://replicate.com/docs/topics/predictions/input-files) [Output files](https://replicate.com/docs/topics/predictions/output-files) [Prediction lifecycle](https://replicate.com/docs/topics/predictions/lifecycle) [Share a prediction](https://replicate.com/docs/topics/predictions/share-a-prediction) [Rate limits](https://replicate.com/docs/topics/predictions/rate-limits) [Safety checking](https://replicate.com/docs/topics/predictions/safety-checking) [Data retention](https://replicate.com/docs/topics/predictions/data-retention) [Streaming output](https://replicate.com/docs/topics/predictions/streaming)

Deployments

[About deployments](https://replicate.com/docs/topics/deployments) [Create a deployment](https://replicate.com/docs/topics/deployments/create-a-deployment) [View deployments](https://replicate.com/docs/topics/deployments/view-deployments) [Delete a deployment](https://replicate.com/docs/topics/deployments/delete-a-deployment)

Webhooks

[About webhooks](https://replicate.com/docs/topics/webhooks) [Set up webhooks](https://replicate.com/docs/topics/webhooks/setup-webhook) [Receive webhooks](https://replicate.com/docs/topics/webhooks/receive-webhook) [Verify webhooks](https://replicate.com/docs/topics/webhooks/verify-webhook) [Test your webhook code](https://replicate.com/docs/topics/webhooks/testing-webhook-code)

Organizations

[About organizations](https://replicate.com/docs/topics/organizations)

Billing

[About billing](https://replicate.com/docs/topics/billing)

Site policy

[About subprocessors](https://replicate.com/docs/topics/site-policy/subprocessors)

Reference

[How does Replicate work?](https://replicate.com/docs/reference/how-does-replicate-work) [Client libraries](https://replicate.com/docs/reference/client-libraries) [HTTP API](https://replicate.com/docs/reference/http) [OpenAPI schema](https://replicate.com/docs/reference/openapi) [Open source](https://replicate.com/docs/reference/open-source)

Close

Popular searches on Replicate

- [Run a model from Node.js](https://replicate.com/docs/get-started/nodejs)
- [Deploy a custom model](https://replicate.com/docs/guides/deploy-a-custom-model)
- [How does Replicate work?](https://replicate.com/docs/reference/how-does-replicate-work)

Showing 0 results